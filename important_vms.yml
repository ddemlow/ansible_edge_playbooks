---
- name: Check clusters for important_vms list from cluster_inventory that should be running - and start in listed (priority) order 
  hosts: edge # use ansible-playbook -l group to limit application to specific groups - has tab completion for -l !
  connection: ansible.builtin.local
  gather_facts: false
  strategy: host_pinned # free  #allows each cluster to start next task before all clusters have finished current task
  environment:  #if set here - hypercore modules will automatically use this for each remote cluster - avoiding need to specify cluster_instance for each test
    SC_HOST: "https://{{ inventory_hostname }}"
    SC_USERNAME: "{{ scale_user | default('admin') }}"
    SC_PASSWORD: "{{ scale_pass | default('admin') }}"
  vars:
    important_vms: |  # list of important vms that should be running (in addition to ansible deployed / managed vms) - also controls start order via playbook
      - github-runner
      - IEAM-westfield
      - acronisAgent
      - adfs-sso
    unimportant_vms: # list of unimportant VM's to stop 
      - junk
      - badVM
    
  tasks:
    - name: Stop unimportant_vms defined in cluster_inventory
      scale_computing.hypercore.vm_params:
        power_state: stop
        vm_name: "{{ item }}"
      loop:  
        "{{ unimportant_vms }}"
      when: unimportant_vms is defined # todo - could also only do this if node is down or condition set?

    - name: Start important_vms defined in cluster_inventory
      scale_computing.hypercore.vm_params:
        power_state: start
        vm_name: "{{ item }}"
      loop:  
        "{{ important_vms | from_yaml }}"
      when: important_vms is defined  # skip if no important_vms set for this cluster in inventory 
# could I also use vm tag in hypercore here?  or if tag = important?
