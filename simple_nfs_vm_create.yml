---
- name: Simple vm deploy #edit vmname variable - use -l filter to specify cluster vs. full inventory
  hosts: edge
  vars:
    - vmname: "nfs-{{site_name}}"
  connection: local
  gather_facts: false
  strategy: host_pinned # free  #allows each cluster to start next task before all clusters have finished current task
  environment:  #if set here - hypercore modules will automatically use this for each remote cluster - avoiding need to specify cluster_instance for each test
    SC_HOST: "https://{{ inventory_hostname }}"
    SC_USERNAME: "{{ scale_user | default('admin') }}"
    SC_PASSWORD: "{{ scale_pass | default('admin') }}"
    SC_TIMEOUT: 60
    
  tasks:
    - name: Ubuntu20_04 template - Ubuntu 20.04 - import if not present # used to clone and cloud-init target VM
      scale_computing.hypercore.vm_import:
        cluster_instance:
          host: "https://{{inventory_hostname }}"
          username: "{{scale_user}}"
          password: "{{scale_pass}}"
        vm_name: ubuntu20_04
        http_uri:
          path: 'https://github.com/ddemlow/RestAPIExamples/raw/master/ubuntu20_04-cloud-init'
          file_name: ubuntu20_04-cloud-init.xml
#      until: ubuntu20_04.msg is search("import complete") #doesnt' check if vm already exists
      retries: 5
      delay: 1
      ignore_errors: false  # import errors are not uncommon depdending on network connection to smb / https source
      register: ubuntu20_04
 

    - name: Clone and configure ad hoc "{{ vmname }}"
      scale_computing.hypercore.vm_clone:
        cluster_instance:
          host: "https://{{inventory_hostname }}"
          username: "{{scale_user}}"
          password: "{{scale_pass}}"
        vm_name: "{{vmname}}"
        source_vm_name: ubuntu20_04
        cloud_init:
          user_data: |
            #cloud-config
            password: "password"
            chpasswd: { expire: False }
            ssh_pwauth: True
            ssh_authorized_keys: # Add your ssh public key for publickey authentication
              - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIDihWWhjoPj8KVLtdLDwNJQ71zi9An0iUFjefRWu2Eju ddemlow@scalecomputing.com
            disable_root: false # allow ssh root login
            ssh_import_id:  gh:ddemlow
            package_update: true
            package_upgrade: true
            packages: [nfs-kernel-server, rpcbind, nfs-common, qemu-guest-agent, unzip]
            runcmd:
              # Ensure rpcbind is enabled and started
              - systemctl enable rpcbind
              - systemctl start rpcbind
              # Create a directory to share via NFS
              - mkdir -p /export/data
              - chmod 777 /export/data
              - chown nobody:nogroup /export/data

              # Configure NFS exports
              - echo "/export/data    *(rw,sync,no_subtree_check)" >> /etc/exports

              # Apply the NFS export configuration
              - exportfs -a

              # Enable and start the NFS server
              - systemctl enable nfs-kernel-server
              - systemctl start nfs-kernel-server
              - [ systemctl, restart, --no-block, qemu-guest-agent ]
            final_message: "The NFS server is ready!"
            bootcmd:
              - [ sh, -c, 'sudo echo GRUB_CMDLINE_LINUX="nomodeset" >> /etc/default/grub' ]
              - [ sh, -c, 'sudo echo GRUB_GFXPAYLOAD_LINUX="1024x768" >> /etc/default/grub' ]
              - [ sh, -c, 'sudo echo GRUB_DISABLE_LINUX_UUID=true >> /etc/default/grub' ]
              - [ sh, -c, 'sudo update-grub' ]
            write_files:
            - content: "{{ inventory_hostname }}"
              path: /clusterip.txt 
          meta_data: |
            dsmode: local
            local-hostname: "{{ vmname }}"

    - name: Disk desired configuration for "{{ vmname }}"
      scale_computing.hypercore.vm_disk:
        cluster_instance:
          host: "https://{{inventory_hostname }}"
          username: "{{scale_user}}"
          password: "{{scale_pass}}"
        vm_name: "{{ vmname }}"
        items:
          - disk_slot: 0
            type: virtio_disk
            size: "{{ '400 GB' | human_to_bytes }}"  # 50GB | human to bytes results in 53.7GB VSD in Hypercore
        state: present

    - name: Vm desired configuration and state for "{{ vmname }}"
      scale_computing.hypercore.vm_params:
        cluster_instance:
          host: "https://{{inventory_hostname }}"
          username: "{{scale_user}}"
          password: "{{scale_pass}}"
        vm_name: "{{vmname}}"
        memory: "{{ '4 GB' | human_to_bytes }}"
        description:
        tags:
          - ansible
          - "{{ site_name }}"
          - ansible_group__"{{vmname}}" # this will create tag used by hypercore inventory plugin when executing towards VM hosts
        vcpu: 4
        power_state: start
